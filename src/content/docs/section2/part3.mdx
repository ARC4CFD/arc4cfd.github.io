---
title: Estimate HPC requirements

bibliography: bibliography.bib
---

import Box from '../../../components/Box.astro';
import MultipleChoice from '../../../components/MultipleChoice.astro';
import Option from '../../../components/Option.astro';
import CustomAside from '../../../components/CustomAside.astro';
import Spoiler from '../../../components/Spoiler.astro';

import Caption from '../../../components/Caption.astro';

:::note[Learning Objectives]
By the end of this section, you should be able to:
1. Estimate the approximate computational cost for a CFD problem.
2. Estimate the required run-time memory and storage.
3. Estimate the resolution requirements for a given physical problem.
4. Determine the parametric space.
:::

## Estimating HPC requirements of CFD simulations: Overview
The objective of this section is to provide a systematic approach for an *a priori* estimate the overall HPC "cost" of a large scale CFD simulation. These estimates are meant to provide guidance, prior to running simulations, in order to better align the run(s) with the available computational ressources. The true costs will depend on a number of other factors such as: type of mesh, meshing software, order of the scheme, user knowledge/experience, and CFD tool, among many others. In this class, we will provide an approach to estimate:
-  the computational mesh size;
- the temporal advancement costs;
- the storage requirements.
Each of these aspects will be separately discussed.
![HPCcompromise.](../../../assets/figs_section2/ARC4CFD_workflow_ESTIMATE.png "Estimate HPC costs of the CFD simulation")


## Estimate grid point requirement
The *a priori* estimate of the grid resolution requirement will help determine the anticipated computational expense of the simulation. These *a priori* estimates do not replace grid sensitivity studies, that are necessary for verification of the CFD simulation results, but are meant to provide an estimate to better plan the HPC resource allocation. The costs for a  CFD campaign are driven by either:

-  large parametric space: a large number of smaller simulations;
- multi-scale nature of the physical problem:  large computational cost per simulation.

For parametric studies, an accurate *a priori* estimate of the grid point requirement is often not necessary as an iterative approach can be done on the individual simulation that is likely be modest in size; in these cases the computational cost comes from the extent of the parametric space that is being investigated.  It is likely more accurate and effective to iteratively find the grid requirement of a single simulation than an *a priori* estimate. Here, we consider the more complex problem of estimating the HPC requirements for a large  simulation  of a multiscale CFD problem. The multiscale nature of the problem is often the reason for the large computational grid; in these cases an iterative approach to find the grid requirement would be too cost prohibitive.  The resolution requirement of these multiscale CFD problems will be driven by:
- boundary layer resolution;
- large-gradients in the freestream;
- multiphase and multiphysics considerations;
- special flow features (transition, separation, shock waves);
- geometric complexity (or large scale separation) in the physical problem.

To illustrate the multiscale nature of typical CFD simulation, we show a [pair of reconnecting, antiparallel vortices](https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/abs/sound-generation-mechanism-of-compressible-vortex-reconnection/F4ED47A4360A583936C971E0A844B594). This figure highglights the necessity to resolve both the smallest scale of the turbulent flow as well as the largest scale, thus, we can quickly see that we are rapidely bound by the scale separation in the problem.
![HPCcompromise.](../../../assets/figs_section2/ARC4CFD_multiscale.png "Estimate HPC costs of the CFD simulation")



### Grid estimate for wall bounded flows
The non-slip condition arising due to the viscous nature of the fluid results in large velocity gradients close to solid walls. Thus, the overall mesh size will be strongly influenced by the required resolution at the wall. The state of the boundary layers will also influence the grid count, therefore we need to consider separately the resolution of :
- laminar boundary layer;
- turbulent boundary layer;
- transitional boundary layer (later in this class).

It should be noted that the resolution of the sharp gradients is necessary to adequately capture the momentum and energy at the wall. Naturally, the resolution is directly influenced by the numerical scheme and modelling considerations in these regions. These estimates are for structures grids but provide an order of magniture estimates that can be used for unstructured meshes as well.
m
#### Estimate for laminar boundary layers
The zero-pressure gradient flat plate boundary layer has the distinct advantage of admitting an analytical solution of the velocity profile: the [Blasius solution](https://en.wikipedia.org/wiki/Blasius_boundary_layer). The Blasius boundary layer is a self-similar solution,  defined in terms of $\eta_y$:   the ratio of wall distance, $y$ and $\delta(x)$ which is proportional to the boundary layer thickness. We can define  as $\eta_y=\frac{y}{\delta(x)}= y\sqrt{\frac{U}{\nu x}}$.  As such, a good estimate of the first grid point in a zero-pressure gradient *laminar* boundary layer will be tied to the ability to fall within the  **nearly** linear region of the Blasius solution close to the wall. 
![HPCcompromise.](../../../assets/figs_section2/ARC4CFD_blasius.png "Estimate HPC costs of the CFD simulation") 


:::tip[Rule of thumb]
A reasonable estimate would be to place the first grid point at  $\eta_y= y\sqrt{\frac{U}{\nu x}}\approx 1$, thus we can  define:

$$y_{\text{first point}}\approx\sqrt{\frac{\nu x}{U}}$$

 where $\nu$, $x$, and $U$ are respectively the dynamic viscosity, streamwise distance of the boundary layer, and the freestream velocity.   If the first point is located farther away from the wall, the linear approximation of the slope at the wall will be incorrect.
 
 If we are interested in accurately capturing the thermal boundary layer (in a laminar flow), we know that:
 	
 	$$ \frac{\delta_{\text{thermal}}}{\delta_{\text{momentum}}} = \frac{1}{Pr^{1/3}}$$
 	
 	Therefore, a laminar case with heat transfer would set the first grid point to meet both the thermal and momentum conditions.
 :::


Let's look at this problem with an example.



<Box iconName='exercise'>
#### Example: laminar boundary layer on flat plate
Consider the very simple case of a zero pressure gradient ($\partial p/\partial x =0$) laminar boundary layer (incompressible) on a flat plate with heat transfer. We provide a sample simulation in SU2 [(which can be download in the git repo)](https://github.com/ARC4CFD/arc4cfd); this case is an adaptation of the [SU2 tutorial case](https://su2code.github.io/tutorials/Inc_Laminar_Flat_Plate/).  Here, we consider a number of different wall normal mesh (keeping the mesh in the streamwise grid spacing constant). First, we look the uniform mesh in the wall normal direction which we discretize with $33$, $65$, $130$ grid points between 0 (wall) and $y=0.03$ m; this corresponds to a first grid point at $y_{\text{first grid}} = 9 \times 10^{-4}$, $4.6 \times 10^{-4}$, and $2.3 \times 10^{-4}$ m, respectively. Then, we consider a stretched grid with points with 33, 50, and 65 grid points. The first grid point and stretching ratios are $1.5 \times 10^{-4}/1.1$, $3.0 \times 10^{-4}$/1.1, and $1.5 \times 10^{-4}/1.04$, respectively, for the 33, 50, and 65 grid point cases. The figure below agregates all the results at a fixed $x$ location in the domain. Note that the non-slip condition is satisfied but the postprocessing outputs the velocity and temperature at the center of the cell.


![HPCcompromise.](../../../assets/figs_section2/ARC4CFD_compareBL.png "Estimate HPC costs of the CFD simulation")
![HPCcompromise.](../../../assets/figs_section2/ARC4CFD_compareBL_T.png "Estimate HPC costs of the CFD simulation")
<Caption>Velocity   and temperature profiles near the wall</Caption>


There are a couple clear take-aways from these results:
1. Stretched grids are essential to minimize the total required grid points (e.g. simulation at 65x130 with uniform grid is about the same as 65x33 stretched grid)
2. The resolution of the velocity boundary layer does not guarantee that the thermal boundary layer will be captured ($Pr=0.72$).

Now, let's try to calculate the total grid points needed to resolve the wall normal direction. Let's use the parameters of the simulation: density ($1.13235$ $kg/m^{3}$), viscosity ($1.834\times^{-5}-5$ $kg/(m s)$), freestream velocity ($69.16$ $m/s$), and we evaluated the boundary layer at $x=0.25$. Therefore, we estimate the boundary layer thickness to be $\delta_{99}\approx 5 \sqrt{\frac{\nu x}{U}} = 0.00128$ m which aligns with the numerical result shown here.

Now, let's estimate the first grid point at the wall:

$$y_{\text{first point}}\approx\sqrt{\frac{\nu x}{U}} \approx 2.42\times 10^{-4} m$$

Based on this estimate, with a uniform mesh, this problem needs approximately 124 grid points in the wall normal direction, whereas this condition can be met on a stretched grid with as few as 33 grid points!  Since we have heat transfer, we should look careful at the Prandtl number  (air typically has $Pr=0.72$) will may impose additional near wall requirement. 

Now that we know the first point, we can estimate the total grid points needed in the laminar boundary layer based on the expansion ratio of the mesh (typically below 1.1). 
</Box>

Now that we have an estimate for the grid requirement for a laminar boundary layer, we 



{/* [ANSYS user guide](https://www.ansys.com/content/dam/amp/2022/february/asset-creation/best-practices-campaign/Best%20Practice-Rans%20turbulence%20modeling%20in%20Ansys%20CFD.pdf)
https://www.tfd.chalmers.se/~lada/comp_turb_model/postscript_files/Quick_Guide_to_Setting_Up_LES_version_1.4_for_Lars.pdf 


In LES grid stretching is set to about:

$$\Delta x^+ (streamwise)=  \Delta z^+ (spanwise) = \phi \Delta y^+ (wall normal)$$

| Syntax      |  $$\phi$$    |
| :---        |          ---: |
| RANS  |         10-100|
| WRLES |     10-100|
| WMLES |     4-10|
| DNS  |     1-2 |
*/}


:::caution[Remember]
Estimating the total computational cost of a numerical simulation **is both science and art**. An exact *a priori* knowledge of the amount of CPU hours required is a very hard task to accomplish, but one can follow a consistent and reliable strategy we outline below
:::


#### Estimate for turbulent boundary layers
As the estimation of grid requirements in a turbulent boundary layer builds on a fundamental understanding of turbulent flow, an *optional* summary of the main concepts in turbulence are provided below. These fundamental concepts of turbulence theory will be used to develop a strategy to estimate the grid requirements in a turbulent boundary layer below.
<CustomAside icon="star" title="Turbulence: main concepts (optional)" colour="green">
<details>
    <summary>Click here for further details</summary>

##### Turbulence
Turbulence is an ubiquitous state of fluid motion that affects our everyday life in many ways. On a macro scale, turbulent flows govern weather changes and the formation and evolution of tropical cyclones; on smaller scale, turbulence affects pollutants transport in the atmosphere or fluid flow in our body. From an engineering standpoint, almost every fluid system of practical interest involves turbulent flows (e.g. flows over bluff/blunt bodies, flows through ducts and pipes, and turbomachines).

The purpose of this section is to give students a general overview of the current state of numerical simulation of turbulent flows with the main goal of educating the audience to a systematic approach to the solution of complex fluids problems. This is far from a complete description of the physiscs and mathematical model of turbulence, to which entire textbooks have been dedicated over the years [Pope (2000)](https://www.cambridge.org/highereducation/books/turbulent-flows/C58EFF59AF9B81AE6CFAC9ED16486B3A#overview), [Durbin et al. (2010)](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470972076).

#### What is turbulence?
Turbulence is a chaotic, irregular state of fluid motion in which the instabilities present in the flow, caused by initial and boundary conditions, are amplified [@piomelli2022vki]. This results in a self-sustaining cycle of *generation* and *destruction* of turbulent **eddies** (regions of high vorticity in the flow). Although chaotic in nature, every turbulent flow displays universal characteristics:
1. **Unsteadiness**: turbulent flows are inherently unsteady. The instantaneous velocity in a turbulent flow when plotted as a function of time might look *random* to any observer unfamiliar with the topic. This randomness is the reason why turbulence research relies on statistical methods.
2. **Three-dimensional**: turbulent flows are highly 3D, even though the flow might have once preferential direction and the resulting **average** velocity might be a function of only two coordinates, the instantaneous velocity fluctuates in all 3 spatial directions.
3. **Mixing**: the presence of instantaneous fluctuations in all directions greately amplifies the mixing of mass, momentum, and energy in the flow. Based on the application of interest enhanced mixing might be a positive outcome (e.g. internal combustion engines), or a negative one (e.g. increase in the skin-friction coefficient and increase in drag force).
4. **Vorticity**: Vorticity is probably the most important and *defining* characteristic of turbulent flows. There are flows in nature that share some common characteristic of turbulence, but are characterized by negligible vorticity; these flows are not turbulent (e.g. random motion of waves on the ocean surface, potential flow over a boundary layer) [@piomelli2022vki].
5. **Dissipative**: Due to the enhanced mixing and vorticity, turbulence bring regions of different momentum (different velocities) into contact resulting in the dumping of velocity gradients through the effect of viscosity. As velocity gradient is reduced, so is the energy content of the flow (or turbulent kinetic energy). Turbulence is a **dissipative** process: if energy is not brough into the flow, turbulence will eventually die. Throughout this process energy is irreversibly transformed to heat.
6. **Multiscale**: As mentioned earlier, turbulent flows are chracterized by the presence of coherent regions of high vorticity, *eddies*. In any turbulent flow, *eddies* span a broad rand of length and time scales. This property of turbulence impacts directly the numerical simulation of turbulent flows and should be given a bit more attention.

#### The scales of turbulence
Whether generated by perturbation in the initial condition or by rapid changes in the geometry, turbulent flows are characterized by a wide distribution of **eddies** of various shapes and sizes. The behaviour of these **eddies** is strongly dependent on their length and velocity scales. Let's consider, for instance, a high-Reynolds number flow with $\mathcal{L}$ and $\mathcal{U}$ its characteristic length and velocity scales, respectively. The Reynolds number is defined as:

$$ Re = \frac{\mathcal{L}\mathcal{U}}{\nu}\gg 1$$

where $\nu$ is the fluid kinematic viscosity. The largest **eddies** in the flow have a length and velocity scales, $L_o$ and $V_o$, comparable to $\mathcal{L}$ and $\mathcal{U}$, therefore their representative Reynolds number $Re_o=L_o V_o/\nu>>1$. On these **eddies** viscosity has little effect as inertia forces dominate, and they are known as **energy carrying eddies**. Their shape is dpendent on the geometry and boundary conditions and they are anisotropic. In turbulent flows, energy is therefore produced at large scales, however, because no dissipation can occur at these large scales, large **eddies** must transfer their energy to smaller and smaller **eddies**. This process was mathematically modelled by the brilliant mathematicians Kolmogorov and today known as the **energy cascade**. As turbulent **eddies** becomes smaller and smaller, their representative Reynolds number decreases, until at the smallest scales $U_\eta$ and $L_\eta$, it becomes of order unity:

$$ Re_\eta = \frac{L_\eta U_\eta}{\nu}\approx 1$$

Viscosity effects now become relevant, and energy is dissipated through viscous dissipation and irreversibly converted to heat. A visual sketch of this complicated process is shown in the figure below.
![Energy cascade.](../../../assets/figs_section2/Energy-cascade.png "Energy cascade.")
<Caption>Energy cascade.</Caption>

:::note[Important to keep in mind]
- Energy is dissipated ONLY at the smallest scales.
- The rate of (how much) energy dissipation is set by the largest scales where production takes place.
- The intermediate scales only *transfer* energy from larger eddies to smaller eddies. 
- As the Reynolds number increases, the separation between the large (integral) and small (dissipative) scales increases.
:::

#### Numerical simulation of turbulent flows
Computational Fluid Dyamics (CFD) for the simulation of turbulent flows is becoming more and more popular as the available computational power of modern computers increases. In the following we will overview the most common approaches followed in CFD, with the idea in mind that the numerical methods requirements greately change based on what one wants to analyze in the flow. 

1. The first and most straight forward approach is to **directly** discretize the equations of motion, and solve them numerically as done in the Poisson equation example in the previous section. This method is commonly referred to as **Direct Numerical Simulation (DNS)**. This method aims at resolving EVERY scale of turbulent motion (integral to dissipative). Assuming that the mesh is fine enough to capture the smallest **eddie** (Kolmogorov scale), one will obtain a 3-dimensional time-dependent solution of the governing equation in which the only source of errors is the one introduced by the numerical methods [Pope (2000)](https://www.cambridge.org/highereducation/books/turbulent-flows/C58EFF59AF9B81AE6CFAC9ED16486B3A#overview).

2. The second very common approach to finding a numerical solution to turbulent flows is to decompose the equations of motion into a **mean** and a **fluctuating** components. This process is known as Reynolds' averaging procedure, where the long-time average of a general quantity $f$ is defiend as $\left\langle f\right\rangle = \frac{1}{T}\int_{t}^{t+T}f\left(\tau\right)d\tau$, where $T$ is a time interval much larger than any time scale in the turbulent flow. Any instantaneous quantity $f$ in the flow, can therefore be taken as the sum of a **mean** annd a **fluctuating** part, $f=\left\langle f\right\rangle + f'$. If one applies the Reynolds decomposition to the equations of motion obtains the well-known **Reynolds-Averaged Navier-Stokes** (RANS) equations which describe the evolution of the mean (large-scale) quantities. Unfortunately, the resulting system of equations is not closed, as the effect of the fluctuating component appears in the Reynolds-stress term and requires the introduction of approximations (turbulence models). A very wide range of models for the Reynolds stresses exists ranging from simple algebraic models, to more complex 2-equations models, to full Reynolds stresses closure models [@piomelli2022vki].

:::tip[Some available techniques to simulate turbulent flows]
1. Direct Numerical Simulation (DNS). All scales of turbulence must be solved.
2. Large-Eddy Simulation (LES). Only the large, energy-carrying eddies are resolved while smaller ones (smaller than a cutoff filter) are modelled using a full closure model. LESs can be Wall-Resolved (WRLES) or Wall-Modelled (WMLES) depending on how the near-wall region is treated.
3. Reynolds-Averaged Navier-Stokes (RANS). The averaged equations for mean quantities are solved, while the Reynolds stresses term is modelled via alebraic one or two-equations models.
:::
</details>

</CustomAside>


The larger velocity gradient of the turbulent boundary layer will result in a smaller grid spacing at the wall than a typical laminar boundary layer. To assess the mininal grid spacing, we recall the typical characteristics of the inner layer of a turbulent boundary layer.  To do so, we recall that we can non-dimensionalize the wall distance $y$ with the viscosity and friction such that we can define: 

$$y^{+}= \frac{y u_{\tau} }{\nu}$$

similarly, we can non-dimensionalize the velocity with the inner layer characteristics velocity, namely the friction velocity:

$$ u^+=\frac{u}{u_\tau}= \frac{u}{\sqrt{\tau_w/\rho}}$$

where $\tau_w$ is the wall shear stress. With these definitions, we can plot the typical velocity profiles of a zero-gradient turbulent  (incompressible) boundary layer often refered to as the **law of the wall** (which formally refers to the logarithmic velocity profile but often used to refer inner-scaled mean velocity profile).

Semilog plot            |  Linear plot
:-------------------------:|:-------------------------:
![HPCcompromise.](../../../assets/figs_section2/ARC4CFD_lawoftheWall_semiLog.png "Estimate HPC costs of the CFD simulation") | ![HPCcompromise.](../../../assets/figs_section2/ARC4CFD_lawoftheWall.png "Estimate HPC costs of the CFD simulation")


The law of the wall is often plotted in a semilog plot (right figure) but the linear plot (right) we clearly see the linearity of the near wall mean velocity profile. To correctly resolve the near velocity profile, the first grid point needs to comfortably fall within the linear sublayer. As such, for wall resolved RANS, LES, and DNS, one should aim to have $y^+\approx 1$ at all locations in the boundary layer, therefore:

$$y_{\text{first point}}\approx\sqrt{\frac{\nu }{u_\tau}}$$

Although, this resolution criterion is the same for all wall resolves models, either in RANS, LES, or DNS, the stretching requirement differs in each case.  

#### Wall resolved simulations
For RANS modelling, we can generally expand the grid with a ratio of up to 1.1, with a minimum of 10 grid points within the boundary layer thickness if the accuracy requirement is not too high, [otherwise 30-40 cells in the wall normal direction would be advised.](https://www.ansys.com/content/dam/amp/2022/february/asset-creation/best-practices-campaign/Best%20Practice-Rans%20turbulence%20modeling%20in%20Ansys%20CFD.pdf). As the turbulence is completely modelled in RANS, the grid requirement in the streamwise and streamwise directions is not as severe and can be stretched:

$$\Delta y^+ (\text{wall normal}) \approx 1; \qquad \Delta x^+ (\text{streamwise}) \approx  \Delta z^+ (\text{spanwise}) < 100 \Delta y^+ (\text{wall normal})$$

In wall-resolved LES (WRLES), only the large eddies must be resolved under the assuption that the dissipative scales ($\eta$) are isotropic, universal, and can be easily modelled. Away from the wall, we can have a coarser grid. 

The ideal near wall resolution is:
$$ \Delta x^+  \approx \Delta y^+  \approx   \Delta z^+ \leq 2 $$
 
 But higher aspect ratio meshes can also provide good results:
 	$$ \Delta y^+ \approx 2 \qquad   \Delta x^+  \approx \Delta z^+  \leq 20 $$

 The estimation of grid resolution requirement in the **outer**  boundary layer is characterized by a length scale proportional to the thickness of the boundary layer $\delta$. A common agreement in the literature shows that to accurately capture the energy-carrying eddies responsible for momentum and energy transport, **at least** 15 points per boundary layer thickness $\delta$ [@piomelli2022vki].  Under these conditions [Choi and Moin (2012)](https://pubs.aip.org/aip/pof/article/24/1/011702/361102/Grid-point-requirements-for-large-eddy-simulation) estimated that the number required to resolve the inner layer is $N_{total}=\left(N_x \times N_y\times Nz\right)\propto Re_x^{13/7}$ for WRLES.

In DNS, all scales of motion, including the dissipative scales ($\eta$) must be resolved.  Since, the smallest isotropic turbulence needs to be accurately resolved, we have a much stricter constraint on the aspect ratio of the mesh:

WHAT IS THE TYPICAL GROWTH RATE IN DNS?

$$ \Delta x^+  \approx \Delta y^+  \approx   \Delta z^+ \leq 2 $$
 
The number of grid points required is therefore proportional to the ratio $L/\eta\approx Re^{3/4}$ where $Re$ is the Reynolds number based on the integral length and velocity scales. The number of grid points required to perform a 3D DNS is $N\approx Re^{9/4}$.



#### Wall functions or wall modelled simulations
Wall functions are often used to reduce to reduce the total grid points near the wall in RANS by completely modeling the near wall velocity and turbulence. In these cases, the first grid point should be set to  $30 < y^+ < 500. This significantly reduces the computational cost of the simulation but also imposes a more important modelling component to the simulation.

The wall-modelled LES (WMLES) similarly reduces the near wall requirement by modeling the characteristics immediately adjacent to the wall. To estimate the grid resolution requirements, we resort to the analysis by [Choi and Moin (2012)](https://pubs.aip.org/aip/pof/article/24/1/011702/361102/Grid-point-requirements-for-large-eddy-simulation) that showed  $N_{total}\propto Re_{x}$ for WMLES (where $x$ is the streamwise dimension of the computational domain). Other works have also analysed the estimated grid scaling requirements in WMLES such as [Larsson et al. (2015)](https://oatao.univ-toulouse.fr/14614/7/Bodart_14614.pdf).


NEED TO INCLUDE [MOIN](https://web.stanford.edu/group/ctr/ResBriefs/2023/24_Agrawal.pdf)

### Grid resolution in the freestream
The grid re


The range of length scales and the sized of the **eddies** in a turbulent flow will determine the grid resolution requirement  the simulation. 





Consider the flow over a backward-facing step (one of the examples in this section) in which a closed separation bubble is formed downstream the step. The largest eddie in the flow is the separation bubble itself, and is characterized by a length scale $L$ proportional to the integral scale of the flow. Depending on the Reynolds number analyzed, a wide range of smaller and smaller eddies is present, the smallest being of size $\eta$.

1. In DNS, all scales of motion, including the dissipative scales ($\eta$) must be resolved. The computational domain must be significantly larger than the largest eddie of dimensions $L$, but the grid size must be of order $\eta$ to capture the tiniest eddie. The number of grid points required is therefore proportional to the ratio $L/\eta\approx Re^{3/4}$ where $Re$ is the Reynolds number based on the integral length and velocity scales. The number of grid points required to perform a 3D DNS is $N\approx Re^{9/4}$.

2.  In a wall-bounded flow, the resolution of the inner layer is driven by the presence of the quasi-streamwise vortices and grid resolution is more demanding [Robinson (1991)](https://www.annualreviews.org/doi/pdf/10.1146/annurev.fl.23.010191.003125).

 




To estimate the overall cost of the numerical simulation one must consider that the equations of motion must be integrated for a time proportional to the integral time-scale of the flow $T$. The time step size $\Delta t$ is a function of the simulation technique used. In DNS, for instance, $\Delta t$ is limited by the need of resolving the life cycle of the smallest eddy of size $\eta$. In LES, a larger time step could be used and will be determined by the size of the smalles resolved eddy. RANS, as expected, has the least restrictive requirement on $\Delta t$ given that it only resolves mean quantities. A good practice on estimating the total cost of a simulation was outlined by Reynolds [Reynolds (2005)](https://link.springer.com/chapter/10.1007/3-540-52535-1_52) who assumed that the operation count scales like the number of points in the domain, and that the time step $\Delta t$ is determined by the stability condition on the Courant–Friedrichs–Lewy (CFL) number, $\Delta t\approx 1/\Delta x$ [@piomelli2022vki]. Given that time integration must be performed for a number of steps proportional to $N_t\approx T/\Delta t$, this results in a total number of steps proportional to $N_t\approx \left(N_x N_y N_z\right)^{1/3}$, and a total computational cost of $\left(N_x N_y N_z\right)^{4/3}\approx Re^3$.



"Free shear flows, like mixing layers, jets or wakes typically require at least ~10 cells normal to the layer. The resolution in stream/spanwise direction is usually of the order of the shear layer thickness."


The computational domain must be significantly larger than the largest eddie of dimensions $L$, but the grid size must be of order $\eta$ to capture the tiniest eddie.

### Multiphase and multiphysics considerations




### Special flow features (transition, separation, shock waves)


https://iopscience.iop.org/article/10.1088/1742-6596/1400/7/077047/pdf



### Geometric complexity

#### Computational cost of the simulation


## Estimating time advancement
The spatial discretization greatly impacts the total computational cost of a simulation but the temporal discretization can also greatly impact. Starting from the intial state, the governing equations will be advanced in time (assuming an unsteady simulation) by a time-step that may be constant or varying. Naturally, the allowable time-step will depend on the minimal timestep constrained by either:

- temporal scheme of the code (numerics);
- characteristic time of the smallest timescale in the problem (physics). 

 Each of timestep limitations will be discussed below.
 
 ### Numerical timestep limitation
 Although implicit methods have clear advantages (especially if the problem is steady state), they typically require pre-conditioners and are often difficult to get good [parallel effeciency on large clusters](https://ntrs.nasa.gov/api/citations/19950023030/downloads/19950023030.pdf). Explicit time advancement methods, on the other hand, are very well-suited for parallel computing but these methods face numerical stability constraints based on the CFL number. The CFL number is defined as:
 	
 	$$CLF=\frac{\mathcal{U} dt}{dx}$$
 	
 where 	$\mathcal{U}$ is the magnitude of the local characteristic velocity at each grid point, $dt$ is the timestep, and $dx$ the local characteristic mesh size. To ensure stability, the maximum CFL number among at all grid points in the domain must be below the stability limit CFL (which depends on the numerics).  There are two main characteristic velocities that can limit the time advancement:
 	- **convective CFL limit**: the most general condition 
 	- **acoustic CFL limit**: typically arises in compressible solver where wave propagation arises
 As the maximum CFL condition will arise at locations in the flow that have the largest local characteristic velocity and the smallest local mesh. If the mesh is well-constructed, the finest mesh should be used in regions of large gradients (typically near the wall), therefore estimations on the timestep will typically focus on identifying the limiting time advancement features of the simulation. For **incompressible simulations**, the time advancement is bound by the convective limit. Thus, assuming a turbulent mean velocity profile, we can explore the effect of the grid stretching ratio on the position of the maximum CFL number in the boundary layer (we assume our first grid point is set to $y^+=1$). 
 
  ![HPCcompromise.](../../../assets/figs_section2/ARC4CFD_turbBL.png "Estimate HPC costs of the CFD simulation")
 
 A similar analysis can be conducted in the laminar boundary layer velocity profile.  If the code does not have the ability of local timesteps (which allows for different timestep size at different spatial locations), the time step can be estimated a priori by:

 	- Assuming a stability limit (typically $CFL<1$);
 	- Based on the mesh estimate, identify the location of maximum CFL;
 	- Compute the total number of time steps needed in the simulation.
 
Although the above approach is generalizable, some workers have proposed scaling analysis to estimate the number of timestep in WRLES: $N_{time}\propto Re_x^{1/7}$  [Yang and Griffin, (2021)](https://pubs.aip.org/aip/pof/article/33/1/015108/1061120/Grid-point-and-time-step-requirements-for-direct).
 
  
 In **compressible simulations**, the time advancement limit is more strongly contrained by the acoustic wave propagation speed ($\mathcal{U}=c$). The relative importance of the acoustic and convective limit can be  characterized by the local Mach number in the flow $M=U/c$. Thus, if $M<<1$, the speed of sound, $c$, will be large relative to the convective speed and the time steps will be acoustically constrainted. Therefore, very low Mach number simulations on fully compressible codes are typically very expensive; in which low-Mach formulations are used which remove the acoustic constraint. 
 
 
 
:::caution[Caution]
This estimate does not consider the viscous stability, and it is strictly valid ONLY for calculations in which at least the diffusion term is treated implicitly. 
:::

One should also be aware of the fact that this estimate is not valid when considering oscillating or pulasting flows in which an external time-scale caused by the amplitude of the oscillation is forced into the flow. In this case the total integration time is a function of the period of the oscillation.

 

 
 <Box iconName='quiz'>
### Problem 1: Finding a maximum dt based on CFL stability constraint
Suppose we have a flat plate turbulent boundary layer with the known characteristics:
- Friction velocity: $u_\tau=0.5$ m/s
- Viscosity $\nu=1.8205 \times 10^{-5}$ kg/(m*s)
Using the 1/7th power law to approximate the turbulent boundary layer ($\bar{u}/u_\tau=8.7(y u_\tau/\nu)^{1/7}$), compute the CFL number if you set the time advancement to $dt=1 \times 10^{-5}$ s and that your first grid point satisfies $y^+=1$ and your grid has an expansion ratio of 1.025.
 (solution in git)
### How much walltime do you need?
<MultipleChoice>
    <Option>
TEST
    </Option>
        <Option>
TEST2
    </Option>
</MultipleChoice>


<details>
    <summary>Problem 1: Solution </summary>


 ![HPCcompromise.](../../../assets/figs_section2/ ARC4CFD_turbBL.png "Estimate HPC costs of the CFD simulation")
</details>


 </Box>
 
 



## Estimating storage requirements
The total storage estimate can be assessed a priori based on the expected number of 'snapshots', the number of parameters needed, and the grid size. Saving simulations to disk can be done in order to: (1) restart the simulation, (2) archive the data, or (3) post-process the simulation. We can estimate the total size of snapshot in binary format.  To do so, we need to consider:

 	- precision (single- or double-precision)
 	- mesh type (structured or unstructured)
 	- output format (e.g. vtk, silo etc.)
 	- number of variables output.

Most of the real variables in modern CFD are double-precision thus take up 64-bit. Some sofware allow outputs to be written in 32-bit which can be beneficial to the overall storage need without much loss in precision. Integers are also output, especially for unstructured mesh formats, to relate faces and grid points. These are usually stored as 32 bit integers, although for very large meshes, 64 bits may be needed, as 32-bits only allows 4,294,967,296 signed integers.

For practical reasons, we propose a simple approach to estimate the minimum size of a single snapshot of a structured mesh. Structured meshes have an implicit connectivity between the mesh points, whereas unstructured meshes must also store the connectivity among each grid point. The present estimate represents the minimum size of the data file. First we list all the variables that are to be output:
 -  coordinates (x, y, z)
 -  velocity ($u$, $v$, $w$)
 - thermodynamics ($p$, $\rho$)
 - multiphase or multiphysics
 - any additional outputs (derivatives etc.)
 
Let's consider an incompressible code for which we need a restart file, to restart the simulation we need at least the coordinates (3), velocity (3), and pressure (1). These need to be written for $N_{total}= N_x \times N_y \times N_z$ grid points. Therefore, the minimum size of a $100^3$ mesh is: 56 MB. Yet, most of the times, the outputs will include additional variables.






<Box iconName='exercise'>
## EXAMPLE: Estimating the HPC costs of the BFS


An *a priori* estimation of the HPC costs of the backward facing step is undertaken. Let's first list out the characteristics of the simulation (from [Jovic and Driver (1994)](https://link.springer.com/article/10.1007/BF00208471)):

- $Re_ \delta = \frac{\rho U  \delta}{\mu}= 5000$
- $Re_\theta = \frac{\rho U \theta}{\mu}= 600$
- $U_0= 7.7 m/s$
- $\delta = 9.65 mm$


From these data, we can compute the viscosity of the fluid:  $\nu= \frac{0.00965 *7.7}{5000} = 0.000014861 m^2/s$ (as the flow is incompressible and constant density, we can assume $\rho=1$). Based on the domain selected (last class), we can make a conservative estimate on the boundary layer length: $30 \delta$ (we can overlook the separated flow region at this stage).  Thus we can compute:

$$Re_x=\frac{ U  x }{\nu}=\frac{ 7.7 \cdot 30\delta}{0.000014861} =150,000$$

First, let's estimate the first grid point in this turbulent flow. We use the  Schlichting skin-friction correlation:

$$C_f = (2 \log (Re_x) - 0.65)^{-2.3} = 0.00072435$$

From the friction coefficient, we can compute the wall shear stress as:

$$\tau_w=C_f \frac{1}{2} \rho U^2_0= \frac{0.00072435}{2}7.7^2= 0.021473$$

The friction velocity can now be estimated:
$$u_\tau=\sqrt{\frac{\tau_w}{\rho}}=\sqrt{0.021473} = 0.146538 $$

If we want a $y^+$ equal to unity, we can compute the distance of the first cell:

$$y_{\text{first point}}= \frac{y^+ \nu}{u_\tau} = \frac{0.000014861}{0.146538} \approx  0.0001 m$$

Assuming a grid stretching ratio of 1.025, from the bottom wall to the top wall of the domain ($6\delta=0.5404 m$) would require about 108 grid points in the wall normal direction, grid stretching calculation can be done [here](https://openfoamwiki.net/index.php/Scripts/blockMesh_grading_calculation).

Now, let's consider the number of grid points required in the streamwise direction. If we accept a stretching ratio of 25 ($\Delta x^+=  \Delta z^+ = 25 \Delta y^+$), then we need:
$$\frac{L_x}{dx} = \frac{30\delta}{25*0.0001 }= 116$$ grid points

Similarly, in the $y$ direction:
$$\frac{L_z}{dz} = \frac{4\delta}{25*0.0001 }=15$$ grid points

Based on these estimates, we require about 186,600 grid points for an LES of this case without considering the shear layer.

<Box iconName='quiz'>
## Problem 1
Suppose you want to simulate a case at a $Re_ \delta=10,000$ estimate the grid requirement. (need to refine example)
### How much walltime do you need?
<MultipleChoice>
    <Option>
TEST
    </Option>
        <Option>
TEST2
    </Option>
</MultipleChoice>



<details>
    <summary>Problem 1: Solution </summary>
   We recall that we can estimate $$\frac{N_{new}}{N} \propto \frac{Re_{new,Lx}^{13/7}}{Re_{Lx}^{13/7}} = \left(\frac{10,000}{5,000}\right)^{13/7}= 3.623$$ (this is wall modelled, careful!, need to revisit)
           </details>
</Box>

</Box>


:::note[Learning Objectives]
Having finished this lecture, you should now be able to answer the following important questions:
1. XXXXXX
:::

