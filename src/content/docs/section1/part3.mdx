---
title: Allocating Resources and Running Jobs Using SLURM
---

import MultipleChoice from '../../../components/MultipleChoice.astro';
import Option from '../../../components/Option.astro';
import CodeFetch from '../../../components/CodeFetch.astro';
import Box from '../../../components/Box.astro';
import CustomIcon from '../../../components/CustomIcon.astro';

:::note[Learning Objectives]
By the end of this section, you should be able to:
1. Successfully allocate resources using SLURM.
2. Run jobs in interactive mode.
3. Run jobs by submitting batch scripts.
4. Use various software (CFD included) on the cluster.
:::

There are two basic ways of allocating resources and running jobs on the cluster using SLURM:
- Requesting various compute resources on which to run your job interactively (supervised).
- Requesting various compute resources on which to run non-interactive jobs (unsupervised).

## Running a job in interactive mode

To allocate resources on the cluster interactively we will use the SLURM command `salloc`. The `salloc` command is used to allocate a SLURM job allocation, which is a set of resources (nodes), possibly with some set of constraints (e.g. number of processors per node, or memory per processor). When `salloc` successfully obtains the requested allocation, it then runs the command specified by the user. Finally, when the user specified command is complete, `salloc` relinquishes the job allocation. 

From the login node type:
```bash
salloc -n 1 --time=0:10:0 --mem-per-cpu=3g --account=account-name
```
As you notice, the `salloc` command requires a few user inputs:
- `-n`: the number of processors.
- `--time`: for how long you are requesting the resources. The format is `hh:mm:ss`.
- `--mem-per-cpu`: amount of memory to assign to each CPU. This is a very important parameter, and it will be clear in later sections of this course how to properly select it.

All these parameters will decide how much time it will take for the queue manager to allocate the resources. For instance, requesting 2 processors will take much less time than requesting 512, and a 10 minutes long job will be allocated much faster than a 20 hours one. Upon pressing enter, the output should be similar to this:

```bash
    salloc: Pending job allocation 24928305
    salloc: job 24928305 queued and waiting for resources
    salloc: job 24928305 has been allocated resources
    salloc: Granted job allocation 24928305
    salloc: Waiting for resource configuration
    salloc: Nodes gra287 are ready for job
```

In these steps SLURM tells us that a job with ID 24928305 has been created for us, that it is in the queue and waiting for resources, and that the resources have been found and granted. Finally, the resources have been configured and a node nc10433 is now ready for our task. You will also notice that the command line prompt name has changed to:

```bash
[username@gra287 ~]$
```

This means we are not sitting anymore on the login node, but we are now **on a compute node** whose identifier is **gra287**. One might ask: **now that I am into a compute node, how do I run my code that is sitting in my `/home` directory?** And here is a beautiful feature of a computer cluster: upon running the `ls` command from the compute node, you will realize that although you are on a complete different node you are still able to see the exact same files and directories you had in your home. That is due to the architecture of the cluster which works with a **distributed shared memory** system. That means you will be able to run your code or access your files from anywhere in the cluster. You can check the status of your job at any time by using the SLURM command `squeue -u username` or simply `sq`. If you open a new command line window, log into Graham and from the login node type `sq`, here is what you'll see:

```bash title="Pending Job"
[username@gra287 ~]$ sq
          JOBID     USER      ACCOUNT           NAME  ST  TIME_LEFT NODES CPUS TRES_PER_N MIN_MEM NODELIST (REASON)
       24928305 username account-name    interactive  PD       9:57     1    1        N/A      3G gra287 (None)
```
```bash title="Running Job"
[username@gra287 ~]$ sq
          JOBID     USER      ACCOUNT           NAME  ST  TIME_LEFT NODES CPUS TRES_PER_N MIN_MEM NODELIST (REASON)
       24928305 username account-name    interactive   R       9:57     1    1        N/A      3G gra287 (None)
```

Some important things to notice:
1. The job name is "interactive", as we were expecting.
2. The status `ST` if pending `PD` in the first extract, and running `R` in the second.
3. The number of nodes and number of CPUs should reflect what was defined by the `salloc` command.

If you want to stop/cancel the job at once, you can use the command `scancel` followed by the job ID. In our case:
```bash
[username@gra287 ~]$ scancel 24928305
```
With the command `salloc` we ran earlier, we requested allocation for 10 minutes. Once the requested time is over, SLURM will automatically release the resources and you will be back to the login node. Here is the message you'll receive when the time is over:

```bash
[username@gra287 ~]$ salloc: Job 24928305 has exceeded its time
         limit and its allocation has been revoked. srun: Job step
         aborted: Waiting up to 62 seconds for job step to finish.
         slurmstepd: error: *** STEP 24928305.interactive ON gra287 
         CANCELLED AT 2024-01-27T23:38:18 DUE TO TIME LIMIT ***
         exit
[username@gra-login2 ~]$ 
```

## What about text editing?
What you might have already noticed, now that we are remotely connected to the remote server, are a couple of problems:
1. There is NO graphic interface (in most cases), and all you see is a terminal window.
2. You will not be able to use your favourite text editor in graphic mode.

**Do not panic!** There are amazing completely free, open-source, screen-based text editors that you can use that are probably already installed on the remote machine. The following is a non exhaustive list of VERY COMMON screen-based text editors:
1. [Nano](https://www.nano-editor.org/)
2. [Emacs](https://www.gnu.org/software/emacs/)
3. [Vim](https://www.vim.org/)

Here, we will focus on [Vim](https://www.vim.org/). Vim (**Vi** i**M**proved) is a completely free, open-source, screen-based, very powerful, and extremely versatile text editor developed by [Bram Moolenaar](https://en.wikipedia.org/wiki/Bram_Moolenaar). First of all, type `vim` on your command line, and this is the output you should see:
```bash
~                                        VIM - Vi IMproved                                          
~                                                                                                   
~                                         version 8.2.360                                           
~                                     by Bram Moolenaar et al.                                      
~                                   Modified by Gentoo-8.2.0360                                     
~                           Vim is open source and freely distributable                             
~                                                                                                   
~                                  Help poor children in Uganda!                                    
~                          type  :help iccf<Enter>       for information                            
~                                                                                                   
~                          type  :q<Enter>               to exit                                    
~                          type  :help<Enter>  or  <F1>  for on-line help                           
~                          type  :help version8<Enter>   for version info 
```

The first thing you realize is that the vim welcome message pops up in the terminal itself and that, from now on, you can take your mouse (or trackpad) and throw it away! You might not agree with it right now, but this is one of the hidden beauties of **Vim**. The welcome message also gives you a couple of VERY useful commands, such as, **how to quit Vim**, and **how to get help**.

### Four Vim modes
The most important thing to realize as soon as Vim starts up is understand in what **mode** is working. There are **4 MAIN modes**:

1. **Normal**: normal mode is the default start-up mode for Vim. This mode is read-only and you will be unable to edit the file. **Very useful when consulting or studying a piece of code**.

2. **Insert**: upon pressing `i` you will enter **insert mode**. In this mode you will be able to freely edit the file. Two very useful sub-commands are: `a` will turn on insert mode and move the cursor after the current character. `o` will turn on insert mode and move the cursor one line below.

3. **Visual**: this mode allows you to visually highlight (slect) text areas and perform operations (cut, copy, move) on them. Press `v` to enter **visual mode** which will mark the beginning of the selection. You can use the arrow keys to highlight the desired text.

4. **Command line**: this mode will allow you to perform operations such as: quit, save, replace, and search. Enter the command line mode by typing `:` within normal mode.

:::tip[The golden rule]
If you do not know in which mode you are in, or if you want to go back to normal mode just press `ESC`. You will find that when you will be more used to using Vim, the `ESC` key will be on of the most used on your keyboard.
:::

### 5 basic commands to get by
Here are the 5 basic commands to use Vim on a daily basis as a beginner. However we strongly suggest a more in-depth analysis of the editor as you will probably gain in workflow efficiency:

1. **The save command**: suppose you are now in insert mode (after typing `i`, `o`, `a`, or `INS` in a full size keyboard) and say that you are happy and want to save the changes to your file, the command to save is `:w` and `ENTER`. If you want to save and quit Vim, you would just type `:wq` and press `ENTER`.

2. **The undo command**: suppose you made some changes, but want to go back, NOT A PROBLEM: within a session Vim keeps track of your changes and you can go back by pressing `u` until the oldest change.

3. **Navigation keys**: Vim is designed to improve your productivity while writing codes. You don't need to use arrow keys (usually placed on the far right of your keyboard) to navigate your code. Within normal mode you can move around using `h` (left), `j` (down), `k` (up), `l` (right). Practice using these keys instead of the arrows and you will never regret it!

4. **Delete line command**: you can delete an entire line by typing `dd` within normal mode. This command will delete the line the cursor is sitting at.

5. **The search command**: there are a few ways in which you can search in Vim. If you activated the line number, you can go directly to a specified line number # by typing `:#` and `ENTER`. You can also perform a word search by typing `/` followed by the word you are searching for. If you press `ENTER` Vim will go to the word you searched that is below and closest to the cursor. At that point if you press `n` repeatedly Vim will jump to every location in the code where that word appears. When you reach the bottom of the code Vim will pop a message in the status bar **“search hit BOTTOM, continuing at TOP”** and will move to the top of the file. By default, search words are not highlighted and the search is case sensitive.

:::note[More about Vim]
<details>
    <summary>Click here</summary>
    Right off the bat you might think Vim looks pretty boring, especially if compared with recent fancy text editors (e.g. Atom, VS code, etc.). By default there is no syntax highlighting, no programming language recognition, and no line number. So, **how do you customize Vim's look?**. There is no dropdown settings menu where you can edit all the perks. **Remember, Vim is meant to work without GUI**. 
    
    At start-up vim automatically reads a config file called `~/.vimrc`. This is the equivalent of your `~/.bashrc` file for your terminal. If you just installed Vim or if you are a brand new user, chances are you do not have this file, so the first thing to do is to create the file at home: `touch ~/.vimrc`.

    Inside this file you can now put all your precious settings to make Vim look very fancy! Here is a selection of settings which I believe will be useful for any Vim user:
    ```bash
    set nocompatible
    filetype on
    filetype indent on
    syntax on
    set number
    set cursorline
    ```
    From top to bottom: **nocompatible** fixes compatibility problems between Vi and Vim, **filetype on** makes sure Vim recognizes the file by the extension and syntax, **indent on** follows indentation rules set by the given programming language, **syntax on** highlights keywords and functions based on the given programming language,** set number** puts the line number on the left side, and **set cursorline** underlines the location where the cursor is.

    **The status bar:** a pretty awesome tool that will give you useful information on the file you are editing with Vim. The status bar is situated at the bottom of the file and can give very useful information on the file we are editing. Here are the changes that must be included in the `~/.vimrc` file to customize the status bar:
    ```bash 
    set statusline=
    set statusline+=\ %F\ %M\ %Y\ %R
    set statusline+=%=
    set laststatus=2 
    ```

    This is **FAR beyond** a complete course on Vim but just a quick showcase of useful commands that may spark your curiosity to use this wonderful tool. To learn more visit the [Vim](https://www.vim.org/) offcial page.
</details>
:::

## Submitting a job

Often times you will need to run many simulations at the same time which may be characterized by the same "running" parameters. If that is the case, running every single simulation in interactive mode is not convenient. The most common way of running a job on the cluster is, in fact, by submitting a batch script to SLURM. Think of it as if you are ordering food at a restaurant: your order is written on a piece of paper (batch script), which is then given to the restaurant manager (queue manager) for execution. Your order might be executed directly or wait in a queue depending on how busy the restaurant is. The batch file is usually divided in two parts:
1. In the first part you will give SLURM all the parameters for the job. Each line containing these parameters must be preceded with `#SBATCH` in the script.
2. In the second part you will specify any commands that must be executed as part of the job.

A very simple batch script might look like this:

```bash frame="none"
#!/bin/bash
#SBATCH -t 0-10:00
#SBATCH --mem=3g
#SBATCH -o output.log

./myfirstjob.py
```

Now that you know how to allocate resources on the cluster, **you are ready to run heavy computations!** However, you might be wondering: **how do I install my CFD package on the cluster?** Here comes yet another, very beautiful feature of most supercomputers, which is the **module system**.

## The module system

The module system is a concept available in most clusters worldwide and guarantees the use of different software (and different versions of the same software) in a precise and controlled manner. In most cases, a supercomputer has far more software installed than the average user will ever need. Therefore, the settings for all these software packages and their supported versions are encapsulated in "environment modules" maintained by the module system. These modules are in no way related to `perl` or `python` modules and should not be confused with that. To have an idea on what modules are already installed on your current profile, from the login node run the command:

```bash
[username@gra-login1 ~]$ module list
```

You will notice that some basic modules such as `openmpi`, `python`, or `intel` are already installed. If the module or software you look for is not in the list of the modules installed, run the command:

```bash
[username@gra-login1 ~]$ module avail
```
to know what modules are available on this particular cluster. What you will notice is that:
1. There are an incredible number of modules available in several different versions.
2. They are very well organized and color coded based on discipline. For instance, `bio` stands for modules in Bioinformatic libraries/apps and `phys` stands for modules in Physics libraries/apps.
3. If you are in the CFD field, there are common softwares such as `starccm`, `openfoam`, and `gmsh`.

Once you have chosen the module you need, all you do is run the command:
```bash
[username@gra-login1 ~]$ module load modulename
```
:::caution
The modules you load will only survive on your profile for the duration of the session. Once you log out of the login node the modules previously loaded will be lost and you will need to reload them again.
:::

However, if you are happy with the loaded module and you know that you will use them constantly, you can run the command:
```bash
    [username@gra-login1 ~]$ module save
```
to save the current module setting as the **default** configuration. There are several other useful commands in the module system environment such as `module purge` to unload all the modules currently installed, and `module switch x y` to switch module `x` with module `y`. And now you are REALLY ready to run you first job on the cluster!

<Box iconName='exercise'>

## Example: my first job
In this very simple example code we check if a specific year is a leap year. **Try running this code on the cluster using all the methods learned so far**.


<CodeFetch rawURL='https://raw.githubusercontent.com/ARC4CFD/arc4cfd/dev/section1/isleap.py' lang='python' meta="title='isleap.py'" />

The first option we have is to run the script directly in the login node. Upon checking if the python module has been loaded, from the login node we simply type:

```bash title="Running from login node" 
[username@gra-login2 ~]$ python ./isleap.py 2024
    2024 is a leap year
```


The second option is to run the script in a compute node in interactive mode. The first step as mentioned previously is allocating the resources:

```bash title="Running in interactive mode"
salloc -n 1 --time=0:10:0 --mem-per-cpu=500m --account=account-name
```
Here we requested a single processor for 10 minutes with 500 Mb of memory (more than enough for the task at hand).

The third and final option is to run the script by submitting a batch script to SLURM. Let's create a file ``firstjob.sh" to give all the necessary information about the job. The batch script will look something like:

```bash frame="none"
#!/bin/bash
    
#SBATCH --job-name=isleap      ## Name of the job
#SBATCH --output=isleap.out    ## Output file
#SBATCH -e isleap.err          ## Error file
#SBATCH --time=10:00           ## Job Duration
#SBATCH --nodes=1              ## Number of nodes
#SBATCH --ntasks=1             ## Number of processors
#SBATCH --mem-per-cpu=100M     ## Memory per CPU required by the job.

## Execute the python script and pass the input '2024'
srun python isleap.py 2024
```

Because the submitted hob will run unsupervised, it is good practice to ask SLURM to produce an **output file** (ileap.out) in which the output of our code will be printed, and an **error file** (isleap.err) in which the error message will be printed in case there is a problem. To run the batch script simply type:

```bash title="Submitting a batch script"
[username@gra-login2 ~]$ sbatch firstjob.sh 
    Submitted batch job 25017005
```

Once again, you can check the status of your simulation by running the command **squeue -u** or **sq**, and upon completion, you will notice that a new file has been created in your current directory named ``isleap.out", the content of which is exactly:

```bash frame="none"
[username@gra-login2 ~]$ cat isleap.out 
    2024 is a leap year
```

You will also notice that the file ``isleap.err" has been created, however its content is empty as no error was encountered during execution. Finally, note that the number of tasks requested of Slurm is the number of processes that will be started by srun. Because this code is not written in parallel mode, if more tasks are selected, the different CPUs will all perform the same operation. **TASK**: in the previous example, modify the batch script to ask for 4 processors, and run the job again. **What does the output look like?**
</Box>

## A bit about performance, AGAIN

We introduced the concept of performance in ``computing" earlier when discussing about **FLOPS** and **clock speed**, however in HPC the term performance has a slight different connotation. Most of the time we are not interested in using the most powerful machine on Earth, but rather we are interested in **making the most** out of the computational power we have available. This concept is very easy to understand with a simple example: say that you are a professional copyist. After your long experience you have optimized your workflow so that you copy an entire page of a manuscript with no difficulty. However, if you are now tasked with copying a 1000-pages manuscript, despite your talent it will probably take you a LONG time, more than any employer will ever wait for. A very simple solution would be to delegate some of the workload to 9 other copyists that could assist you (while of course communicating between each other), increasing the chances of getting the work done much faster.

As we have seen earlier, especially in CFD, the workload can increase by orders of magnitude by just stepping from a 2D simulation to a 3D domain. In very simple terms, our goal will be to distribute the workload **effectively** and **efficiently** over the resources we have available, in order to reach the final result in a reasonable time frame. In HPC terminology there are 2 key definitions we need to be very comfortable with:

1. **Walltime**: or more precisely ``elapsed real time" is the length of time, measured in seconds, that a program takes to run (e.g. execute all its assigned tasks). The walltime is **independent** of how many resources are used; it is the time it takes according to a clock mounted on the wall. This distinction is very important as the way a machine measures time, and how it is perceived by the user may be different.

2. **CPU hours**: is the amount of CPU time spent processing. Imagine, for example, to execute a program for a walltime of 1 hour on 32 CPUs. **We will have used up to 32 CPU hours**. This concept is also very important, as the allocation a given user has on a cluster is usually measured in CPU hours.

Now the question left to answer is **can we improve performance?** This will be the basis of the next section, and the answer is YES. If you are taking this course, you are probably an **application user** and not an **application developer**, meaning that you are not really interested in developing more efficient CFD tools, but rather in using your favourite CFD package as efficiently as possible. If that is the case, you have two ways of improving the performance: (i) use more nodes and consequently more CPUs will allow us to tackle a larger workload, and (ii) reducing the frequency of **file writing** in the code. When performing very long computations sometimes is useful to take an "instantaneous snapshot" to check progress and to make sure everything is running as expected, however it can be quite expensive. Reducing the frequency of file writing can have a surprisingly positive impact on the overall performance.



<Box iconName='quiz'>
## Problem 1
Assuming that you are using 2 complete nodes to run your simulation. Each node has 32 CPUs. You will be in the office for only 8 hours. **Answer the following questions**:

### How much walltime do you need?
<MultipleChoice>
    <Option>
        32 hours of walltime
    </Option>
    <Option isCorrect>
        8 hours of walltime
    </Option>
    <Option>
        16 hours of walltime
    </Option>
</MultipleChoice>

### How many CPU hours would you need?
<MultipleChoice>
    <Option>
        256 CPU hours 
    </Option>
    <Option>
        8 CPU hours
    </Option>
    <Option isCorrect>
        512 CPU hours
    </Option>
</MultipleChoice>

### What would be the batch script you'd submit to SLURM?

<details>
    <summary>Show solution</summary>
    ```bash
        #!/bin/bash  
        #SBATCH --job-name=problem1    ## Name of the job
        #SBATCH --time=08:00:00        ## Job Duration hh:mm:ss
        #SBATCH --nodes=2              ## Number of nodes
        #SBATCH --ntasks=64            ## Number of processors
    ```
</details>
</Box>

:::note[Learning Objectives]
Having finished this lecture, you should now be able to answer the following important questions:
1. How do I run a job in interactive mode on the cluster?
2. How do I submit a batch script to SLURM?
3. How do I load my favorite CFD software?
:::